# Visual AI Service Deployment (Optional)
# Provides visual comparison and self-healing capabilities
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: visual-ai-config
  namespace: testforge
data:
  VJEPA_HOST: "0.0.0.0"
  VJEPA_PORT: "50052"
  MODEL_PATH: "/models/vjepa"
  SIMILARITY_THRESHOLD: "0.85"
  BATCH_SIZE: "4"
  MAX_WORKERS: "2"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: visual-ai
  namespace: testforge
  labels:
    app: visual-ai
spec:
  replicas: 1
  selector:
    matchLabels:
      app: visual-ai
  template:
    metadata:
      labels:
        app: visual-ai
    spec:
      containers:
        - name: visual-ai
          image: testforge/visual-ai:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 50052
              name: grpc
          envFrom:
            - configMapRef:
                name: visual-ai-config
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "4Gi"
              cpu: "2000m"
              # Uncomment for GPU support
              # nvidia.com/gpu: 1
          volumeMounts:
            - name: models
              mountPath: /models
          livenessProbe:
            grpc:
              port: 50052
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            grpc:
              port: 50052
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: models
          emptyDir: {}
          # For production, use persistent storage:
          # persistentVolumeClaim:
          #   claimName: visual-ai-models-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: visual-ai
  namespace: testforge
spec:
  selector:
    app: visual-ai
  ports:
    - port: 50052
      targetPort: 50052
      name: grpc
  type: ClusterIP
